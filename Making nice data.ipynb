{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a store of all the data so that we can quickly access it. This took about half an hour to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "city = 'STLOUIS'\n",
    "store = pd.HDFStore('{c}/store.h5'.format(c=city))\n",
    "months={4:'April', 5:'May', 6:'June', 7:'July',8:'August', 9:'September'}\n",
    "\n",
    "for m in months.keys():\n",
    "    for y in range(2002, 2016):\n",
    "        path = '../../data/{c}/BOX/'.format(c=city)\n",
    "        def dateparse(Y, m, d, H, M):\n",
    "            d = pd.datetime(int(Y), int(m), int(d), int(H), int(M))\n",
    "            return d\n",
    "\n",
    "        df = pd.read_csv(path+'StLouis_box_radar_{yyyy}_{mm:02d}.csv'.format(yyyy=y, mm=m),\n",
    "                         header=None, sep = ',', na_values = '-99',\n",
    "                         parse_dates={'date_time': [0,1,2,3,4]},\n",
    "                         date_parser=dateparse, index_col=[0])\n",
    "        df.columns = range(0,19600)\n",
    "        store['{c}_{yyyy}_{mm:02d}'.format(c=city, yyyy=y, mm=m)] = df\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also store computed values that we feel we will be accessing a lot. This one takes a while too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from radar import Radar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "months={4:'April', 5:'May', 6:'June', 7:'July',8:'August', 9:'September'}\n",
    "monthly_mean = {}\n",
    "\n",
    "for m in months.keys():\n",
    "    to_stack = []\n",
    "    for y in range(2001, 2016):\n",
    "        c = Radar('Charlotte', t=pd.datetime(y, m, 4), how='hdf5')\n",
    "        to_stack.append(np.nanmean(c.box, axis=0)*4)\n",
    "    monthly_mean.update({m: np.nanmean(np.stack(to_stack), axis=0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "computed = pd.HDFStore('computed.h5')\n",
    "monthly_mean_df = pd.DataFrame([v.flatten() for v in monthly_mean.values()], index=monthly_mean.keys())\n",
    "computed['monthly_mean_df'] = monthly_mean_df\n",
    "computed.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the store of all the data it is pretty quick to make this other store of the big events. Now we will be able to load really quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "city = 'CHARLOTTE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TOP50 = pd.read_csv('{c}/TOP50_events.csv'.format(c=city), parse_dates=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for n in range(50):\n",
    "    top = pd.HDFStore('{c}/TOP50.h5'.format(c=city))\n",
    "    store = pd.HDFStore('{c}/store.h5'.format(c=city))\n",
    "    y = TOP50.t_begin[n].year\n",
    "    m = TOP50.t_begin[n].month\n",
    "    d = TOP50.t_begin[n].day\n",
    "    fname = '{c}_{yyyy}_{mm:02d}'.format(c=city, yyyy=y, mm=m)\n",
    "    df = store[fname]\n",
    "    top['storm_{yyyy}_{mm:02d}_{dd:02d}'.format(yyyy=y, mm=m, dd=d)] = df[TOP50.t_begin[n]:TOP50.t_end[n]]\n",
    "    top.close()\n",
    "    store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the nice peak time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Peak time of exceedance\n",
    "peak_time={2:np.zeros([96,140,140], dtype=np.int32),\n",
    "           10:np.zeros([96,140,140], dtype=np.int32),\n",
    "           25:np.zeros([96,140,140], dtype=np.int32),\n",
    "           50:np.zeros([96,140,140], dtype=np.int32)}\n",
    "\n",
    "for n in range(50):\n",
    "    c = Radar(city, TOP50.t_begin[n], how='hdf5', store='{c}/TOP50.h5', make_rate=4)\n",
    "    for thresh in [2, 10, 25, 50]:\n",
    "        b = c.box>thresh\n",
    "        for ix in range(0,140):\n",
    "            for iy in range(0,140):\n",
    "                q = c.time[b[:,iy,ix]].hour*60+c.time[b[:,iy,ix]].minute\n",
    "                for i, t in enumerate(range(0, 60*24, 15)):\n",
    "                    peak_time[thresh][i,iy,ix]+=np.sum(q==t)\n",
    "computed = pd.HDFStore('{c}/computed.h5'.format(c=city))\n",
    "for thresh in [2,10,25,50]:\n",
    "    p = pd.Panel(peak_time[thresh])\n",
    "    computed['peak_time_TOP50_{thresh}'.format(thresh=thresh)] = p\n",
    "computed.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
