{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roadmap\n",
    "\n",
    "The goal of this notebook is to provide an example of how to scrape NEXRAD level II data and use pyart and csu_radar_tools to calculate radar rainfall estimates at rain gage locations during a storm. Inspiration from the discussion [here](https://groups.google.com/forum/#!msg/pyart-users/dxw0Mm7-SzI/iRI3-yXxDQAJ)\n",
    "\n",
    "  1. Genarate mock rain gage data\n",
    "  2. Download available NEXRAD data\n",
    "  5. Download sounding data\n",
    "  6. Classify hydrometeors\n",
    "  7. Compute rainfall estimate\n",
    "  8. Interpolate radially\n",
    "  9. Pull out rainfall estimates at gage locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before getting started, set up your environment with all the necessities to run this notebook. To create this environment just run **`$ conda env create -f environment.yml`** where **`environment.yml`** is a file containing the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat environment.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mock rain gage data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ID='KTLH'\n",
    "latitude = 30.39758301\n",
    "longitude = -84.32894135\n",
    "\n",
    "year=2016\n",
    "month=9\n",
    "day=2\n",
    "hour=2\n",
    "\n",
    "t_start = '2016-09-02 02:00'\n",
    "t_end = '2016-09-02 04:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:                 (station: 50, time: 10)\n",
      "Coordinates:\n",
      "  * time                    (time) datetime64[ns] 2016-09-02T02:00:00 ...\n",
      "  * station                 (station) |S3 'G1' 'G2' 'G3' 'G4' 'G5' 'G6' 'G7' ...\n",
      "    lat                     (station) float64 31.92 31.8 31.48 32.22 31.78 ...\n",
      "    lon                     (station) float64 -82.84 -82.73 -83.31 -83.19 ...\n",
      "Data variables:\n",
      "    rain_gage_accumulation  (station, time) float64 0.0 0.0 0.0 0.0 0.0 0.0 ...\n",
      "CPU times: user 23.9 ms, sys: 696 Âµs, total: 24.6 ms\n",
      "Wall time: 44.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "netcdf=True\n",
    "\n",
    "gage_times = pd.date_range(pd.datetime(year, month, day, hour), freq='15min', periods=10, tz='UTC')\n",
    "gage_locs = np.random.rand(50,2)*2+ np.array([latitude, longitude])\n",
    "gage_data = np.zeros((gage_times.shape[0], gage_locs.shape[0]))\n",
    "gage_names = ['G'+str(i) for i in range(1, gage_locs.shape[0]+1)]\n",
    "\n",
    "gage_df_data = pd.DataFrame(index=gage_times, data=gage_data, columns=gage_names)\n",
    "gage_df_locs = pd.DataFrame(index=gage_names, data=gage_locs, columns=['lat', 'lon'])\n",
    "\n",
    "if not netcdf:\n",
    "    gage_df = pd.concat([gage_df_locs, gage_df_data.T], axis=1)\n",
    "    gage_df.head()\n",
    "\n",
    "def to_da(i, name, gage_data, gage_times):\n",
    "    return xr.DataArray(gage_data[:,i], name=name, dims={'time': gage_times.shape},\n",
    "                        coords={'time': gage_times.astype('datetime64[ns]'), 'station':name})\n",
    "\n",
    "datasets = [to_da(i, name, gage_data, gage_times) for i, name in enumerate(gage_names)]\n",
    "combined = xr.concat(datasets, 'station')\n",
    "ds0 = combined.to_dataset(name='rain_gage_accumulation')\n",
    "\n",
    "gage_df_locs.index.name='station'\n",
    "ds_gage = ds0.merge(xr.Dataset(gage_df_locs))\n",
    "ds_gage.set_coords(['lat', 'lon'], inplace=True)\n",
    "print(ds_gage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pyart\n",
    "\n",
    "from pyart_radar_tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached file ...\n",
      "./tmp/KTLH20160902_015528_V06\n",
      "using cached file ...\n",
      "./tmp/KTLH20160902_020138_V06\n",
      "using cached file ...\n",
      "./tmp/KTLH20160902_020748_V06\n",
      "using cached file ...\n",
      "./tmp/KTLH20160902_021359_V06\n",
      "using cached file ...\n",
      "./tmp/KTLH20160902_022009_V06\n",
      "using cached file ...\n",
      "./tmp/KTLH20160902_022617_V06\n",
      "using cached file ...\n",
      "./tmp/KTLH20160902_023228_V06\n",
      "using cached file ...\n",
      "./tmp/KTLH20160902_023838_V06\n",
      "using cached file ...\n",
      "./tmp/KTLH20160902_024448_V06\n",
      "using cached file ...\n",
      "./tmp/KTLH20160902_025125_V06\n",
      "using cached file ...\n",
      "./tmp/KTLH20160902_025803_V06\n",
      "using cached file ...\n",
      "./tmp/KTLH20160902_030439_V06\n",
      "using cached file ...\n",
      "./tmp/KTLH20160902_031116_V06\n",
      "using cached file ...\n",
      "./tmp/KTLH20160902_031754_V06\n",
      "using cached file ...\n",
      "./tmp/KTLH20160902_032431_V06\n",
      "using cached file ...\n",
      "./tmp/KTLH20160902_033108_V06\n",
      "using cached file ...\n",
      "./tmp/KTLH20160902_033746_V06\n",
      "using cached file ...\n",
      "./tmp/KTLH20160902_034426_V06\n",
      "using cached file ...\n",
      "./tmp/KTLH20160902_035104_V06\n"
     ]
    }
   ],
   "source": [
    "paths = data_download(ID, t_start, t_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sounding\n",
    "\n",
    "Optionally you can get data from a nearby sounding in the UWyo format (i.e., from http://weather.uwyo.edu/upperair/sounding.html), and copy and paste it into a txt file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skewt import SkewT\n",
    "sounding = SkewT.Sounding('./tmp/sounding.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fields = ['rain', 'r_kdp', 'r_z']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run\n",
    "First we need to import the tools from pyart_radar_tools, then we can process all the radar files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_radar(path, sounding, run_QAQC=True,\n",
    "                  min_dist_km=5, max_dist_km=250,\n",
    "                  sw_vel=True, max_time_diff=30):\n",
    "    radar = pyart.io.read(path)\n",
    "    radar = extract_low_sweeps(radar)\n",
    "\n",
    "    # run some QAQC:\n",
    "    if run_QAQC:\n",
    "        start_gate = get_gate_index(radar, dist_km=min_dist_km)\n",
    "        end_gate = get_gate_index(radar, dist_km=max_dist_km)\n",
    "        QAQC_mask = construct_QAQC_mask(radar, start_gate, end_gate,\n",
    "                                        sw_vel=sw_vel,\n",
    "                                        max_time_diff=max_time_diff)\n",
    "\n",
    "    # get out just the sweeps with differential phase values\n",
    "    radar = extract_field_sweeps(radar, field='differential_phase')\n",
    "\n",
    "    # do computations\n",
    "    radar = calculate_hidro_rain(radar, sounding)\n",
    "    radar = calculate_rain_nexrad(radar)\n",
    "    radar = calculate_rain_kdp(radar)\n",
    "    if run_QAQC:\n",
    "        for field in ['rain', 'r_kdp', 'r_z']:\n",
    "            radar = interpolate_radially(radar, field, QAQC_mask,\n",
    "                                         start_gate, end_gate)\n",
    "    return radar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('processing', './tmp/KTLH20160902_015528_V06')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsignell/miniconda2/envs/radar/lib/python2.7/site-packages/numpy/ma/core.py:4144: UserWarning: Warning: converting a masked element to nan.\n",
      "  warnings.warn(\"Warning: converting a masked element to nan.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('processing', './tmp/KTLH20160902_020138_V06')\n",
      "('processing', './tmp/KTLH20160902_020748_V06')\n",
      "('processing', './tmp/KTLH20160902_021359_V06')\n",
      "('processing', './tmp/KTLH20160902_022009_V06')\n",
      "('processing', './tmp/KTLH20160902_022617_V06')\n",
      "('processing', './tmp/KTLH20160902_023228_V06')\n",
      "('processing', './tmp/KTLH20160902_023838_V06')\n",
      "('processing', './tmp/KTLH20160902_024448_V06')\n",
      "('processing', './tmp/KTLH20160902_025125_V06')\n",
      "('processing', './tmp/KTLH20160902_025803_V06')\n",
      "('processing', './tmp/KTLH20160902_030439_V06')\n",
      "('processing', './tmp/KTLH20160902_031116_V06')\n",
      "('processing', './tmp/KTLH20160902_031754_V06')\n",
      "('processing', './tmp/KTLH20160902_032431_V06')\n",
      "('processing', './tmp/KTLH20160902_033108_V06')\n",
      "('processing', './tmp/KTLH20160902_033746_V06')\n",
      "('processing', './tmp/KTLH20160902_034426_V06')\n",
      "('processing', './tmp/KTLH20160902_035104_V06')\n",
      "CPU times: user 10min 23s, sys: 7.99 s, total: 10min 31s\n",
      "Wall time: 10min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "radar0 = pyart.io.read(paths[0])\n",
    "netcdf=True\n",
    "gage_dict={}\n",
    "for gage_name in gage_names:\n",
    "    if netcdf:\n",
    "        latitude = ds_gage.lat.sel(station=gage_name).values\n",
    "        longitude = ds_gage.lon.sel(station=gage_name).values\n",
    "    else:\n",
    "        latitude = gage_df.loc[gage_name, 'lat']\n",
    "        longitude = gage_df.loc[gage_name, 'lon']\n",
    "    x_disp, y_disp = find_x_y_displacement(radar0, longitude, latitude)\n",
    "    gage_dict.update({gage_name: {'x_disp': x_disp, 'y_disp': y_disp}})\n",
    "\n",
    "sweep_times = []\n",
    "sweep_stacks = []\n",
    "for path in paths:\n",
    "    print('processing', path)\n",
    "    radar = process_radar(path, sounding)\n",
    "\n",
    "    for sweep in range(radar.nsweeps):\n",
    "        # get time\n",
    "        end_sweep_time = get_end_sweep_time(radar, sweep)\n",
    "        sweep_times.append(end_sweep_time)\n",
    "        \n",
    "        # get data at point\n",
    "        sweep_stack = retrieve_points(radar, sweep, fields, gage_dict)\n",
    "        sweep_stacks.append(sweep_stack)\n",
    "c = np.stack(sweep_stacks, axis=2)\n",
    "\n",
    "cols = ['gate_lon', 'gate_lat', 'gate_altitude']\n",
    "cols.extend(fields)\n",
    "d = {'time': {'dims': ('time'), 'data': sweep_times},\n",
    "     'station': {'dims': ('station'), 'data': gage_names}}\n",
    "for i, name in enumerate(cols):\n",
    "    d.update({name: {'dims': ('station', 'time'), 'data': c[i]}})\n",
    "ds_radar = xr.Dataset.from_dict(d)\n",
    "ds_radar.set_coords(['gate_altitude', 'gate_lat', 'gate_lon'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_radar_15 = ds_radar[fields].resample('15min', 'time', label='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ds = ds_gage.merge(ds_radar_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ds.rain.mean('station').plot(c='g')\n",
    "ds.r_z.mean('station').plot(c='b')\n",
    "ds.r_kdp.mean('station').plot(c='r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
